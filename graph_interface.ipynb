{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c054774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# specify .env path, containing LANGCHAIN_PROJECT, LANGCHAIN_TRACING_V2 (\"true\"), LANGSMITH_API_KEY, OPENAI_API_KEY\n",
    "%load_ext dotenv\n",
    "%dotenv .env \n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph_sdk import get_sync_client\n",
    "from langgraph.pregel.remote import RemoteGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from llm_plan.workflow import State, build_graph\n",
    "from urllib.parse import quote\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797d4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-agent blocksworld\n",
    "initial_description = (\n",
    "    \"Two agents are tasked with manipulating blocks arranged in stacks on a table, from one configuration to another. \"\n",
    "    \"Each block is uniquely labelled by a letter. Both agents can only interact with blocks at the top of each stack, \"\n",
    "    \"and only interact with one block at a time. Additionally, one agent can only interact with vowel blocks, \"\n",
    "    \"and the other can only interact with consonant blocks. Initially there are blocks A, B, C, D, E, F, G, I. D, E are directly on the table. \"\n",
    "    \"C is on top of D, B is on top of C, A is on top of B, G is on top of E, I is on top of G, and F is on top of I. At any point, each agent can only be holding at most one block, and the other agent\" \n",
    "    \"cannot put a block on top of it if it's being held. \"\n",
    "    \"The goal is to have C and G directly on the table, with B on top of C, A on top of B, D on top of G, I on top of G, F on top of I, and E on top of F.\"\n",
    "    \"Finally, there cannot be more than 3 stacks on the table at any time, and both agents know this.\"\n",
    "    ) # user NL description of planning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c24e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meeting planning\n",
    "initial_description = \"You are an expert at scheduling meetings. You are given a few constraints on the existing schedule of each participant, the meeting duration, and possibly some preferences on the meeting time. Note there exists a solution that works with existing schedule of every participant. Here are a few example tasks and solutions:\\n\\nTASK: You need to schedule a meeting for Michelle, Steven and Jerry for one hour between the work hours of 9:00 to 17:00 on Monday. \\n\\nHere are the existing schedules for everyone during the day: \\nMichelle has meetings on Monday during 11:00 to 12:00; \\nSteven has blocked their calendar on Monday during 9:00 to 9:30, 11:30 to 12:00, 13:30 to 14:00, 15:30 to 16:00; \\nJerry has blocked their calendar on Monday during 9:00 to 9:30, 10:00 to 11:00, 11:30 to 12:30, 13:00 to 14:30, 15:30 to 16:00, 16:30 to 17:00; \\n\\nFind a time that works for everyone's schedule and constraints. \\nSOLUTION: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e87a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose direct or pddl mode. If single agent, must use direct.\n",
    "initial_state: State = {\n",
    "    \"messages\": [HumanMessage(content=initial_description)],\n",
    "    \"multi_agent\": True,\n",
    "    \"mode\": \"direct\",\n",
    "    \"refinement_iters\": 5, \n",
    "    \"enable_clarifications\": False, \n",
    "    \"WSL\": True\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\"thread_id\": \"nbk-run-002\"},\n",
    "    \"tags\": [\"notebook_manual\"],\n",
    "    \"run_name\": \"LangGraph-notebook-manual_run\",\n",
    "    \"metadata\": {\"dataset\": \"dev\", \"purpose\": \"test\"},\n",
    "}\n",
    "# whether to use studio\n",
    "REMOTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5366f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view in studio, run langgraph dev then this cell\n",
    "SERVER = \"http://127.0.0.1:2024\"\n",
    "client = get_sync_client(url=SERVER)\n",
    "\n",
    "# see langgraph.json for available graphs\n",
    "remote = RemoteGraph(\"workflow\", url=SERVER)\n",
    "\n",
    "thread = client.threads.create()\n",
    "config[\"configurable\"][\"thread_id\"] = thread[\"thread_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa45393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing event: Clarifier\n",
      "Executing event: Reworder\n",
      "Executing event: JSON coder\n",
      "Executing event: Task Environment Constructor\n",
      "Executing event: Workflow splitter\n",
      "Executing event: Actor node\n",
      "Executing event: Init refiner state\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Meta analyst\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Meta analyst\n",
      "Executing event: Select refiner\n",
      "Executing event: NL converter\n"
     ]
    }
   ],
   "source": [
    "if REMOTE:\n",
    "    g = remote\n",
    "else:\n",
    "    cp = MemorySaver()\n",
    "    g = build_graph().compile(checkpointer=cp)\n",
    "\n",
    "try:\n",
    "    for event in g.stream(initial_state, config=config):\n",
    "        event_name = next(iter(event))\n",
    "        print(f\"Executing event: {event_name}\")\n",
    "        if event_name == \"__interrupt__\":\n",
    "            if REMOTE:\n",
    "                questions = event[\"__interrupt__\"][0][\"value\"].get(\"questions\", [])\n",
    "            else:\n",
    "                questions = event[\"__interrupt__\"][0].value.get(\"questions\", [])\n",
    "            if questions:\n",
    "                print(\"Clarification questions:\")\n",
    "                for q in questions:\n",
    "                    print(f\"- {q}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Streaming interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f82936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [\n",
    "    \"They don't need to place on the table first, but should pick up and put down as two separate actions.\",\n",
    "    \"No.\"\n",
    "    \"They cannot move simultaneously.\",\n",
    "    \"No additional rules.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "992bbced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing event: Oracle\n",
      "Executing event: Reworder\n",
      "Executing event: JSON coder\n",
      "Executing event: Task Environment Constructor\n",
      "Executing event: Workflow splitter\n",
      "Executing event: Actor node\n",
      "Executing event: Actor node\n",
      "Executing event: Workflow splitter\n",
      "Executing event: Actor node\n",
      "Executing event: Init refiner state\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n",
      "Executing event: Select refiner\n",
      "Executing event: Refiner\n"
     ]
    }
   ],
   "source": [
    "# Resume streaming\n",
    "try:\n",
    "    for event in g.stream(Command(resume=answers), config=config):\n",
    "        event_name = next(iter(event))\n",
    "        print(f\"Executing event: {event_name}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Streaming interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced14266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume without streaming\n",
    "g.invoke(Command(resume=answers), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd1f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_studio_for_thread(config: dict, base_url: str=\"http://127.0.0.1:2024\", open_browser: bool=True) -> str:\n",
    "    \"\"\"\n",
    "    Get a LangGraph Studio URL for your local server and current thread, optionally opens in browser\n",
    "    Args:\n",
    "        config: the config used to run, must include config['configurable']['thread_id']\n",
    "        base_url: where the local graph server is (default: http://127.0.0.1:2024)\n",
    "        open_browser: if True, attempt to open the URL in default browser\n",
    "    \"\"\"\n",
    "    thread_id = (config or {}).get(\"configurable\", {}).get(\"thread_id\")\n",
    "    if not thread_id:\n",
    "        raise ValueError(\"No thread_id found in config['configurable']['thread_id'].\")\n",
    "\n",
    "\n",
    "    studio_base = \"https://smith.langchain.com/studio/\"\n",
    "    qs = f\"?baseUrl={quote(base_url)}\"\n",
    "    if thread_id:\n",
    "        qs += f\"&threadId={quote(str(thread_id))}\"\n",
    "\n",
    "    url = studio_base + qs\n",
    "    print(\"LangGraph Studio link:\")\n",
    "    print(url)\n",
    "    print(\"\\nThread ID:\", thread_id)\n",
    "\n",
    "    if open_browser:\n",
    "        try:\n",
    "            webbrowser.open(url)\n",
    "        except Exception as e:\n",
    "            print(\"Could not auto-open browser:\", e)\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2239aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph Studio link:\n",
      "https://smith.langchain.com/studio/?baseUrl=http%3A//127.0.0.1%3A2024&threadId=nbk-run-002\n",
      "\n",
      "Thread ID: nbk-run-002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/studio/?baseUrl=http%3A//127.0.0.1%3A2024&threadId=nbk-run-002'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_studio_for_thread(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18f4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Two agents are tasked with manipulating blocks arranged in stacks on a table, from one configuration to another. Each block is uniquely labelled by a letter. Both agents can only interact with blocks at the top of each stack, and only interact with one block at a time. Additionally, one agent can only interact with vowel blocks, and the other can only interact with consonant blocks. Initially there are blocks A, B, C, O. A is on the table. B is on top of A, and C and O are on the table. The goal is to have A on the table, B on the table, C on top of O, and O on top of B.',\n",
       "  'additional_kwargs': {},\n",
       "  'response_metadata': {},\n",
       "  'type': 'human',\n",
       "  'name': None,\n",
       "  'id': '11383e91-bcea-412c-96b2-3adc0a59c360',\n",
       "  'example': False},\n",
       " {'content': 'I need to clarify a few points to ensure there is enough information to make a plan:\\n\\n1. Can the agents move blocks directly from one stack to another, or do they need to place them on the table first?\\n2. Are there any restrictions on the number of moves each agent can make?\\n3. Can the agents work simultaneously, or do they need to take turns?\\n4. Is there a specific order in which the blocks need to be moved to achieve the final configuration?',\n",
       "  'additional_kwargs': {'refusal': None},\n",
       "  'response_metadata': {'token_usage': {'completion_tokens': 98,\n",
       "    'prompt_tokens': 281,\n",
       "    'total_tokens': 379,\n",
       "    'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'reasoning_tokens': 0,\n",
       "     'rejected_prediction_tokens': 0},\n",
       "    'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "   'model_name': 'gpt-4o-2024-08-06',\n",
       "   'system_fingerprint': 'fp_f33640a400',\n",
       "   'id': 'chatcmpl-CCVoOBXrlPHlnS8OMBW0MqQdaO8XY',\n",
       "   'service_tier': 'default',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None},\n",
       "  'type': 'ai',\n",
       "  'name': None,\n",
       "  'id': 'run--f0a9bf30-2092-44a1-985c-ca546d82d8cd-0',\n",
       "  'example': False,\n",
       "  'tool_calls': [],\n",
       "  'invalid_tool_calls': [],\n",
       "  'usage_metadata': {'input_tokens': 281,\n",
       "   'output_tokens': 98,\n",
       "   'total_tokens': 379,\n",
       "   'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "   'output_token_details': {'audio': 0, 'reasoning': 0}}},\n",
       " {'content': '**Task Brief: Block Manipulation by Two Agents**\\n\\n**Objective:** Rearrange blocks from their initial configuration to a specified goal configuration using two agents with specific interaction constraints.\\n\\n**Initial Configuration:**\\n- Blocks: A, B, C, O\\n- Arrangement:\\n  - A is on the table.\\n  - B is on top of A.\\n  - C is on the table.\\n  - O is on the table.\\n\\n**Goal Configuration:**\\n- A is on the table.\\n- B is on the table.\\n- C is on top of O.\\n- O is on top of B.\\n\\n**Agent Constraints:**\\n- **Agent 1:** Can only interact with blocks labeled with vowels (A, O).\\n- **Agent 2:** Can only interact with blocks labeled with consonants (B, C).\\n\\n**Rules:**\\n- Both agents can only manipulate the top block of any stack.\\n- Each agent can only move one block at a time.\\n\\n**Task Requirements:**\\n- Develop a step-by-step plan for the agents to achieve the goal configuration while adhering to their interaction constraints.',\n",
       "  'additional_kwargs': {'refusal': None},\n",
       "  'response_metadata': {'token_usage': {'completion_tokens': 221,\n",
       "    'prompt_tokens': 185,\n",
       "    'total_tokens': 406,\n",
       "    'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'reasoning_tokens': 0,\n",
       "     'rejected_prediction_tokens': 0},\n",
       "    'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "   'model_name': 'gpt-4o-2024-08-06',\n",
       "   'system_fingerprint': 'fp_f33640a400',\n",
       "   'id': 'chatcmpl-CCVoUwX0mCMFXMF6WROtCGM7AY0xP',\n",
       "   'service_tier': 'default',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None},\n",
       "  'type': 'ai',\n",
       "  'name': None,\n",
       "  'id': 'run--d846c95d-73eb-4e7a-9618-f28f03efbee7-0',\n",
       "  'example': False,\n",
       "  'tool_calls': [],\n",
       "  'invalid_tool_calls': [],\n",
       "  'usage_metadata': {'input_tokens': 185,\n",
       "   'output_tokens': 221,\n",
       "   'total_tokens': 406,\n",
       "   'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "   'output_token_details': {'audio': 0, 'reasoning': 0}}},\n",
       " {'content': '```json\\n{\\n    \"name\": \"BlockManipulation\",\\n    \"author\": \"Human\",\\n    \"agents\": {\\n        \"number\": 3,\\n        \"names\": [\\n            \"agent1\",\\n            \"agent2\",\\n            \"orchestrator\"\\n        ],\\n        \"agent_details\": {\\n            \"agent1\": {\\n                \"private_information\": [\\n                    \"Can only interact with blocks labeled with vowels (A, O).\"\\n                ],\\n                \"goal\": \"Rearrange blocks A and O to achieve the goal configuration.\"\\n            },\\n            \"agent2\": {\\n                \"private_information\": [\\n                    \"Can only interact with blocks labeled with consonants (B, C).\"\\n                ],\\n                \"goal\": \"Rearrange blocks B and C to achieve the goal configuration.\"\\n            },\\n            \"orchestrator\": {\\n                \"private_information\": [],\\n                \"goal\": \"Coordinate agent1 and agent2 to achieve the goal configuration.\"\\n            }\\n        }\\n    },\\n    \"environment\": {\\n        \"init\": {\\n            \"blocks\": [\"A\", \"B\", \"C\", \"O\"],\\n            \"arrangement\": {\\n                \"A\": \"table\",\\n                \"B\": \"A\",\\n                \"C\": \"table\",\\n                \"O\": \"table\"\\n            }\\n        },\\n        \"goal\": {\\n            \"arrangement\": {\\n                \"A\": \"table\",\\n                \"B\": \"table\",\\n                \"C\": \"O\",\\n                \"O\": \"B\"\\n            }\\n        },\\n        \"public_information\": [\\n            \"Blocks: A, B, C, O\",\\n            \"Initial arrangement: A is on the table, B is on top of A, C is on the table, O is on the table.\",\\n            \"Goal arrangement: A is on the table, B is on the table, C is on top of O, O is on top of B.\"\\n        ]\\n    },\\n    \"workflow\": {\\n        \"participants\": {\\n            \"agent1\": {\\n                \"task\": \"pddl\",\\n                \"input\": [],\\n                \"output\": \"pddl_agent1\",\\n                \"system_prompt\": \"You are an expert in PDDL planning. You always provide a PDDL domain and a PDDL problem file that describes the planning problem. Respect the given constraints. Enclose the domain in <domain></domain> tags, and the problem in <problem></problem> tags.\",\\n                \"prompt\": \"Your name is agent1. You are in an environment with the following public information:\\\\n{environment->public_information}\\\\nYou have the following knowledge and/or constraints:\\\\n{agents->agent1->private_information}\\\\nThis is the global goal:\\\\n{environment->goal}\\\\nThink step by step and provide a PDDL domain and a PDDL problem file that encapsulates this problem. Do not make assumptions beyond the given information.\"\\n            },\\n            \"agent2\": {\\n                \"task\": \"pddl\",\\n                \"input\": [],\\n                \"output\": \"pddl_agent2\",\\n                \"system_prompt\": \"You are an expert in PDDL planning. You always provide a PDDL domain and a PDDL problem file that describes the planning problem. Respect the given constraints. Enclose the domain in <domain></domain> tags, and the problem in <problem></problem> tags.\",\\n                \"prompt\": \"Your name is agent2. You are in an environment with the following public information:\\\\n{environment->public_information}\\\\nYou have the following knowledge and/or constraints:\\\\n{agents->agent2->private_information}\\\\nThis is the global goal:\\\\n{environment->goal}\\\\nThink step by step and provide a PDDL domain and a PDDL problem file that encapsulates this problem. Do not make assumptions beyond the given information.\"\\n            },\\n            \"orchestrator\": {\\n                \"task\": \"pddl\",\\n                \"input\": [\\n                    \"pddl_agent1\",\\n                    \"pddl_agent2\"\\n                ],\\n                \"output\": \"pddl_orchestrator\",\\n                \"system_prompt\": \"You are an expert with multi-agent PDDL problems. You always provide a PDDL domain and a PDDL problem file that describes the planning problem. Enclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags. Keep the actions for different agents distinct, so that there is no confusion as to which agent performs which action.\",\\n                \"prompt\": \"Your name is orchestrator. You receive the PDDL domain and problem files from two agents as input. Initial information about the environment: {environment->init}. Goal for the environment: {environment->goal}. Combine the agents\\' PDDLs coherently to respect all constraints. Think step by step and provide a PDDL domain and problem that encapsulate the integrated model. Do not make assumptions beyond the given information. Keep in mind that the PDDL files you receive may be partial or contain ambiguities.\"\\n            }\\n        },\\n        \"order_constraints\": [\\n            \"agent1.pddl->orchestrator.pddl\",\\n            \"agent2.pddl->orchestrator.pddl\"\\n        ]\\n    }\\n}\\n```',\n",
       "  'additional_kwargs': {'refusal': None},\n",
       "  'response_metadata': {'token_usage': {'completion_tokens': 1053,\n",
       "    'prompt_tokens': 3108,\n",
       "    'total_tokens': 4161,\n",
       "    'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'reasoning_tokens': 0,\n",
       "     'rejected_prediction_tokens': 0},\n",
       "    'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "   'model_name': 'gpt-4o-2024-08-06',\n",
       "   'system_fingerprint': 'fp_f33640a400',\n",
       "   'id': 'chatcmpl-CCVoYPmM5O0hoI5Cf50311oxP7rV4',\n",
       "   'service_tier': 'default',\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None},\n",
       "  'type': 'ai',\n",
       "  'name': None,\n",
       "  'id': 'run--a21bdebf-97b6-470e-b46d-eb2174d2aeb2-0',\n",
       "  'example': False,\n",
       "  'tool_calls': [],\n",
       "  'invalid_tool_calls': [],\n",
       "  'usage_metadata': {'input_tokens': 3108,\n",
       "   'output_tokens': 1053,\n",
       "   'total_tokens': 4161,\n",
       "   'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "   'output_token_details': {'audio': 0, 'reasoning': 0}}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect any field of the final graph state\n",
    "field = \"messages\"\n",
    "final_state = remote.get_state({\"configurable\": {\"thread_id\": config[\"configurable\"][\"thread_id\"]}}).values[field]\n",
    "final_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
