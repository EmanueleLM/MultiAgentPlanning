{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human specification\n",
    "import inspect\n",
    "\n",
    "environment_name = \"TwoAgentsVault\"\n",
    "specification = inspect.cleandoc(\"\"\"\\\n",
    "                Two agents are tasked with manipulating blocks arranged in stacks on a table, from one configuration to another. \n",
    "                Each block is uniquely labelled by a letter. Both agents can only interact with blocks at the top of each stack, and only interact with one block at a time. \n",
    "                Additionally, one agent can only interact with vowel blocks, and the other can only interact with consonant blocks. \n",
    "                Initially there are blocks A, B, C, O. A is on the table. B is on top of A, and C and O are on the table. \n",
    "                The goal is to have A on the table, B on the table, C on top of O, and O on top of B.\n",
    "                \"\"\")  # This prompt is ignored if the environment_name already corresponds to an existing environment.\n",
    "format = \"json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environments/static/TwoAgentsVault.json already exists. Skipping generation.\n",
      "[Warning]: The prompt `specification` will be ignored!\n"
     ]
    }
   ],
   "source": [
    "# Generate the json representation of the environment\n",
    "from pathlib import Path\n",
    "\n",
    "from src.llm_plan.planner import Planner\n",
    "from src.llm_plan.llm import ChatGPT\n",
    "from src.llm_plan.config import ENVIRONMENTS_JSON_PATH\n",
    "from src.llm_plan.utils import run_pddl_popf2_and_Val, run_pddl_fast_downwards_and_uVal\n",
    "\n",
    "target_solver = \"FastDownwards\"  # Could be \"FastDownwards\" or \"POPF2\"\n",
    "solver = (run_pddl_fast_downwards_and_uVal if target_solver == \"FastDownwards\" else \"POPF2\")\n",
    "\n",
    "model_json = ChatGPT(\"gpt-5-mini\")  # This is one of the many models you can use now\n",
    "planner = Planner()\n",
    "\n",
    "plan_path = Path(f\"{environment_name}.{format}\")\n",
    "full_path = ENVIRONMENTS_JSON_PATH / plan_path\n",
    "\n",
    "# Skip if the plan already exists\n",
    "if not full_path.exists():\n",
    "    planner.generate_representation(model_json, specification, environment_name, format=format, target_solver=target_solver)\n",
    "else:\n",
    "    print(f\"{full_path} already exists. Skipping generation.\")\n",
    "    print(\"[Warning]: The prompt `specification` will be ignored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan:\n",
      " [['key_holder.pddl', 'small_robot.pddl'], ['orchestrator.pddl']]\n"
     ]
    }
   ],
   "source": [
    "# Generate the environment plan\n",
    "from src.llm_plan.environment import Environment\n",
    "\n",
    "env = Environment(f\"./environments/static/{environment_name}.json\")\n",
    "print(\"Plan:\\n\", env.plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the first plan.\n",
      "Running Fast Downwards and uVAL in tmp/TwoAgentsVault.\n"
     ]
    }
   ],
   "source": [
    "# Start generating the first domain and problem\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from src.llm_plan.hypervisor import Hypervisor\n",
    "from src.llm_plan.config import VALIDATOR_BIN, SOLVER_POPF2_BINARY\n",
    "from src.llm_plan.parser import PDDLParser\n",
    "\n",
    "model_first_plan = ChatGPT(\"gpt-4o\")  # powerful model for the first plan\n",
    "model_plan = ChatGPT(\"gpt-4o\")  # switch to a less powerful model for planning\n",
    "\n",
    "pddl_parser = PDDLParser()\n",
    "\n",
    "BASE_FOLDER = Path(f\"./tmp/{env.name}\")\n",
    "BASE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Fist plan to collect domain and problem\n",
    "# Check if problem_0 and domain_0 already exist\n",
    "if (BASE_FOLDER / f\"problem_0.pddl\").exists() and (BASE_FOLDER / f\"domain_0.pddl\").exists():\n",
    "    print(f\"A plan for {env.name} already exist. Loading domain and problem.\")\n",
    "    with open(BASE_FOLDER / f\"domain_0.pddl\", \"r\") as f:\n",
    "        domain = f.read()\n",
    "    with open(BASE_FOLDER / f\"problem_0.pddl\", \"r\") as f:\n",
    "        problem = f.read()\n",
    "\n",
    "else:\n",
    "    print(\"Generating the first plan.\")\n",
    "    responses = planner.plan(model_first_plan, env)\n",
    "    final_plan = responses[\"pddl_orchestrator\"]\n",
    "    domain, problem = pddl_parser.parse(final_plan, from_file=False)\n",
    "    \n",
    "    # Save domain and problem\n",
    "    with open(BASE_FOLDER / f\"domain_0.pddl\", \"w\") as f:\n",
    "        f.write(domain)\n",
    "    with open(BASE_FOLDER / f\"problem_0.pddl\", \"w\") as f:\n",
    "        f.write(problem)\n",
    "    \n",
    "    \n",
    "# Generate the first plan\n",
    "result = solver(\n",
    "    BASE_FOLDER,\n",
    "    BASE_FOLDER / f\"domain_0.pddl\",\n",
    "    BASE_FOLDER / f\"problem_0.pddl\",\n",
    "    BASE_FOLDER / f\"sas_plan_0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_specification': 'Two agents are tasked with manipulating blocks arranged in stacks on a table, from one configuration to another. \\nEach block is uniquely labelled by a letter. Both agents can only interact with blocks at the top of each stack, and only interact with one block at a time. \\nAdditionally, one agent can only interact with vowel blocks, and the other can only interact with consonant blocks. \\nInitially there are blocks A, B, C, O. A is on the table. B is on top of A, and C and O are on the table. \\nThe goal is to have A on the table, B on the table, C on top of O, and O on top of B.', 'plan': 'No plan yet.', 'specification': {'name': 'TwoAgentsVault', 'author': 'Human', 'agents': {'number': 3, 'names': ['key_holder', 'small_robot', 'orchestrator'], 'key_holder': {'private_information': ['I have a key', 'I am a big robot'], 'goal': 'Open the vault and grab the object inside.'}, 'small_robot': {'private_information': ['I am a small robot'], 'goal': 'Open the vault and grab the object inside.'}, 'orchestrator': {'private_information': [], 'goal': 'Open the vault and grab the object inside.'}}, 'environment': {'init': {'grid_size': 4, 'visibility': 1}, 'public_information': ['There is a vault in the environment.', 'The vault is closed.', 'The vault requires a key to be opened.', 'The entrance of the vault is small.']}, 'workflow': {'key_holder': {'pddl': {'input': [], 'output': 'pddl_key_holder', 'system_prompt': 'You are an expert with PDDL problems (Planning Domain Definition Language). You always provide a PDDL domain and a PDDL problem file to solve the task. You always enclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags.', 'prompt': 'Your name is key_holder. You are in an environment with the following public information:\\n{environment->public_information}\\nYou have the following knowledge:\\n{agents->key_holder->private_information}\\nThis is the global goal to solve:\\n{agents->key_holder->goal}\\nThink step by step and and provide a PDDL domain and a PDDL problem file to solve the task.\\nIf you miss some information, do not make assumptions, just give a plan that concerns the information you have.\\nEnclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags.'}}, 'small_robot': {'pddl': {'input': [], 'output': 'pddl_small_robot', 'system_prompt': 'You are an expert with PDDL problems (Planning Domain Definition Language). You always provide a PDDL domain and a PDDL problem file to solve the task. You always enclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags.', 'prompt': 'Your name is small_robot. You are in an environment with the following public information:\\n{environment->public_information}\\nYou have the following knowledge:\\n{agents->small_robot->private_information}\\nThis is the global goal to solve:\\n{agents->small_robot->goal}\\nThink step by step and and provide a PDDL domain and a PDDL problem file to solve the task.\\nIf you miss some information, do not make assumptions, just give a plan that concerns the information you have.\\nEnclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags.'}}, 'orchestrator': {'pddl': {'input': ['pddl_key_holder', 'pddl_small_robot'], 'output': 'pddl_orchestrator', 'system_prompt': 'You are an expert with multi-agent PDDL problems (Planning Domain Definition Language). You always provide a PDDL domain and a PDDL problem file to solve the task. You always enclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags. If there are multiple-agents, you keep their actions distinct.', 'prompt': \"There are two agents in an environment that are planning to solve a task. You will receive their PDDL domains and problems. You have to orchestrate them to solve the following task:\\n{agents->orchestrator->goal}\\nKeep in mind that the PDDL they send you may be partial or contain ambiguities.\\nA partial PDDL may partially solve a planning problem, but it may require to integrate additional information from the other PDDL to achieve the goal.\\nAmbiguities may appear in different forms: for example, two PDDL problems may refer to the same object with different names  (e.g., a door for an agent is the entrance for the other).\\nHere's the information the first agent has and its PDDL response:\\n{pddl_key_holder}\\nHere's the information the second agent has and its PDDL response:\\n{pddl_small_robot}\\nYou need to integrate the PDDL responses of the two agents to solve the task. It is really important that you keep the actions of the two agents distinct.\\nThink step by step and and provide a PDDL domain and a PDDL problem file to solve the task.\\nEnclose the pddl domain between <domain></domain> tags, and the pddl problem between <problem></problem> tags.\"}}, 'constraints': ['key_holder.pddl->orchestrator.pddl', 'small_robot.pddl->orchestrator.pddl']}}, 'pddl_domain': '(define (domain vault-operation-coordination)\\n  (:requirements :strips :typing)\\n  (:types robot location object key)\\n\\n  (:predicates\\n    (vault_closed)\\n    (vault_open)\\n    (have_key)\\n    (object_grabbed)\\n    (key_inserted)\\n    (small_entrance)\\n    (at ?r - robot ?l - location)\\n    (has-key ?r - robot)\\n    (object_inside)\\n    (grabbed-object ?r - robot)\\n  )\\n\\n  ; Actions for big robot\\n  (:action insert_key\\n    :parameters (?r - robot)\\n    :precondition (and (vault_closed) (have_key) (small_entrance) (at ?r entrance))\\n    :effect (and (key_inserted) (not (vault_closed)))\\n  )\\n\\n  (:action open_vault\\n    :precondition (and (key_inserted) (not (vault_closed)))\\n    :effect (vault_open)\\n  )\\n\\n  ; Actions for small robot\\n  (:action move-to-vault\\n    :parameters (?r - robot)\\n    :precondition (at ?r entrance)\\n    :effect (at ?r vault)\\n  )\\n\\n  (:action use-key\\n    :parameters (?r - robot)\\n    :precondition (and (at ?r vault) (has-key ?r) (not (vault_open)))\\n    :effect (vault_open)\\n  )\\n\\n  (:action grab-object\\n    :parameters (?r - robot)\\n    :precondition (and (at ?r vault) (vault_open) (object_inside))\\n    :effect (grabbed-object ?r)\\n  )\\n)', 'pddl_problem': '(define (problem open-vault-coordinated)\\n  (:domain vault-operation-coordination)\\n  (:objects\\n    big_robot small_robot - robot\\n    entrance vault - location\\n    key - key\\n    object - object\\n  )\\n  (:init\\n    (vault_closed)\\n    (have_key)\\n    (small_entrance)\\n    (at big_robot entrance)\\n    (at small_robot entrance)\\n    (has-key small_robot)\\n    (object_inside)\\n    (not (vault_open))\\n  )\\n  (:goal\\n    (grabbed-object small_robot)\\n  )\\n)', 'target_solver': 'FastDownwards', 'pddl_plan': '(move-to-vault small_robot)\\n(use-key small_robot)\\n(grab-object small_robot)\\n; cost = 3 (unit cost)\\n', 'syntax_errors': '/bin/sh: 1: ./solvers/universal-planning-validator/validator/validate.bin: not found\\n', 'pddl_logs': \"INFO     planner time limit: None\\nINFO     planner memory limit: None\\n\\nINFO     Running translator.\\nINFO     translator stdin: None\\nINFO     translator time limit: None\\nINFO     translator memory limit: None\\nINFO     translator command line string: /home/emanuele/MultiAgentPlanning/.venv/bin/python3 /home/emanuele/MultiAgentPlanning/solvers/fast-downward-24.06.1/builds/release/bin/translate/translate.py tmp/TwoAgentsVault/domain_0.pddl tmp/TwoAgentsVault/problem_0.pddl --sas-file output.sas\\nParsing...\\nParsing: [0.010s CPU, 0.002s wall-clock]\\nNormalizing task... [0.000s CPU, 0.000s wall-clock]\\nInstantiating...\\nGenerating Datalog program... [0.000s CPU, 0.000s wall-clock]\\nNormalizing Datalog program...\\nNormalizing Datalog program: [0.000s CPU, 0.003s wall-clock]\\nPreparing model... [0.000s CPU, 0.000s wall-clock]\\nGenerated 18 rules.\\nComputing model... [0.000s CPU, 0.000s wall-clock]\\n40 relevant atoms\\n14 auxiliary atoms\\n54 final queue length\\n56 total queue pushes\\nCompleting instantiation... [0.000s CPU, 0.000s wall-clock]\\nInstantiating: [0.000s CPU, 0.004s wall-clock]\\nComputing fact groups...\\nFinding invariants...\\n8 initial candidates\\nFinding invariants: [0.000s CPU, 0.000s wall-clock]\\nChecking invariant weight... [0.000s CPU, 0.000s wall-clock]\\nInstantiating groups... [0.000s CPU, 0.000s wall-clock]\\nCollecting mutex groups... [0.000s CPU, 0.000s wall-clock]\\nChoosing groups...\\n7 uncovered facts\\nChoosing groups: [0.000s CPU, 0.000s wall-clock]\\nBuilding translation key... [0.000s CPU, 0.000s wall-clock]\\nComputing fact groups: [0.000s CPU, 0.001s wall-clock]\\nBuilding STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]\\nBuilding dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]\\nBuilding mutex information...\\nBuilding mutex information: [0.000s CPU, 0.000s wall-clock]\\nTranslating task...\\nProcessing axioms...\\nSimplifying axioms... [0.000s CPU, 0.000s wall-clock]\\nTranslator axioms removed by simplifying: 0\\nProcessing axioms: [0.000s CPU, 0.000s wall-clock]\\nTranslating task: [0.000s CPU, 0.000s wall-clock]\\n0 effect conditions simplified\\n0 implied preconditions added\\nDetecting unreachable propositions...\\n0 operators removed\\n0 axioms removed\\n5 propositions removed\\nDetecting unreachable propositions: [0.000s CPU, 0.000s wall-clock]\\nReordering and filtering variables...\\n4 of 6 variables necessary.\\n0 of 1 mutex groups necessary.\\n6 of 8 operators necessary.\\n0 of 0 axiom rules necessary.\\nReordering and filtering variables: [0.000s CPU, 0.000s wall-clock]\\nTranslator variables: 4\\nTranslator derived variables: 0\\nTranslator facts: 8\\nTranslator goal facts: 1\\nTranslator mutex groups: 0\\nTranslator total mutex groups size: 0\\nTranslator operators: 6\\nTranslator axioms: 0\\nTranslator task size: 32\\nTranslator peak memory: 31824 KB\\nWriting output... [0.000s CPU, 0.000s wall-clock]\\nDone! [0.010s CPU, 0.008s wall-clock]\\ntranslate exit code: 0\\n\\nINFO     Running search (release).\\nINFO     search stdin: output.sas\\nINFO     search time limit: None\\nINFO     search memory limit: None\\nINFO     search command line string: /home/emanuele/MultiAgentPlanning/solvers/fast-downward-24.06.1/builds/release/bin/downward --search 'let(hlm,landmark_sum(lm_factory=lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(one),pref=false),let(hff,ff(transform=adapt_costs(one)),lazy_greedy([hff,hlm],preferred=[hff,hlm],cost_type=one,reopen_closed=false)))' --internal-plan-file tmp/TwoAgentsVault/sas_plan_0 < output.sas\\n[t=0.000207s, 9960 KB] reading input...\\n[t=0.000396s, 9960 KB] done reading input!\\n[t=0.002131s, 10224 KB] Initializing landmark sum heuristic...\\n[t=0.002204s, 10224 KB] Generating landmark graph...\\n[t=0.002229s, 10224 KB] Building a landmark graph with reasonable orders.\\n[t=0.002246s, 10224 KB] Initializing Exploration...\\n[t=0.002269s, 10224 KB] Generating landmarks using the RPG/SAS+ approach\\n[t=0.002341s, 10224 KB] Landmarks generation time: 0.000112s\\n[t=0.002359s, 10224 KB] Discovered 6 landmarks, of which 0 are disjunctive and 0 are conjunctive.\\n[t=0.002374s, 10224 KB] 5 edges\\n[t=0.002389s, 10224 KB] approx. reasonable orders\\n[t=0.002411s, 10224 KB] Landmarks generation time: 0.000199s\\n[t=0.002435s, 10224 KB] Discovered 6 landmarks, of which 0 are disjunctive and 0 are conjunctive.\\n[t=0.002452s, 10224 KB] 5 edges\\n[t=0.002467s, 10224 KB] Landmark graph generation time: 0.000276s\\n[t=0.002483s, 10224 KB] Landmark graph contains 6 landmarks, of which 0 are disjunctive and 0 are conjunctive.\\n[t=0.002498s, 10224 KB] Landmark graph contains 5 orderings.\\n[t=0.002544s, 10224 KB] Simplifying 6 unary operators... done! [5 unary operators]\\n[t=0.002573s, 10224 KB] time to simplify: 0.000042s\\n[t=0.002591s, 10224 KB] Initializing additive heuristic...\\n[t=0.002605s, 10224 KB] Initializing FF heuristic...\\n[t=0.002661s, 10224 KB] Building successor generator...done!\\n[t=0.002715s, 10224 KB] peak memory difference for successor generator creation: 0 KB\\n[t=0.002731s, 10224 KB] time for successor generation creation: 0.000011s\\n[t=0.002747s, 10224 KB] Variables: 4\\n[t=0.002762s, 10224 KB] FactPairs: 8\\n[t=0.002777s, 10224 KB] Bytes per state: 4\\n[t=0.002823s, 10224 KB] Conducting lazy best first search, (real) bound = 2147483647\\n[t=0.002881s, 10356 KB] New best heuristic value for landmark_sum_heuristic: 3\\n[t=0.002897s, 10356 KB] New best heuristic value for ff: 4\\n[t=0.002912s, 10356 KB] g=0, 1 evaluated, 0 expanded\\n[t=0.002935s, 10356 KB] Initial heuristic value for landmark_sum_heuristic: 3\\n[t=0.002950s, 10356 KB] Initial heuristic value for ff: 4\\n[t=0.002972s, 10356 KB] New best heuristic value for landmark_sum_heuristic: 2\\n[t=0.002989s, 10356 KB] New best heuristic value for ff: 2\\n[t=0.003004s, 10356 KB] g=1, 2 evaluated, 1 expanded\\n[t=0.003027s, 10356 KB] New best heuristic value for landmark_sum_heuristic: 1\\n[t=0.003042s, 10356 KB] New best heuristic value for ff: 1\\n[t=0.003056s, 10356 KB] g=2, 3 evaluated, 2 expanded\\n[t=0.003076s, 10356 KB] Solution found!\\n[t=0.003093s, 10356 KB] Actual search time: 0.000247s\\nmove-to-vault small_robot (1)\\nuse-key small_robot (1)\\ngrab-object small_robot (1)\\n[t=0.003109s, 10356 KB] Plan length: 3 step(s).\\n[t=0.003109s, 10356 KB] Plan cost: 3\\n[t=0.003109s, 10356 KB] Expanded 3 state(s).\\n[t=0.003109s, 10356 KB] Reopened 0 state(s).\\n[t=0.003109s, 10356 KB] Evaluated 4 state(s).\\n[t=0.003109s, 10356 KB] Evaluations: 8\\n[t=0.003109s, 10356 KB] Generated 11 state(s).\\n[t=0.003109s, 10356 KB] Dead ends: 0 state(s).\\n[t=0.003109s, 10356 KB] Number of registered states: 4\\n[t=0.003109s, 10356 KB] Int hash set load factor: 4/4 = 1.000000\\n[t=0.003109s, 10356 KB] Int hash set resizes: 2\\n[t=0.003109s, 10356 KB] Search time: 0.000287s\\n[t=0.003109s, 10356 KB] Total time: 0.003109s\\nSolution found.\\nPeak memory: 10356 KB\\nRemove intermediate file output.sas\\nsearch exit code: 0\\n\\nINFO     Planner time: 0.12s\\n\", 'history': []}\n",
      "Agent:  AgentSyntaxPDDL\n",
      "Generating the plan with the agent.\n"
     ]
    }
   ],
   "source": [
    "# Refine the plan\n",
    "\n",
    "# Args for the hypervisor\n",
    "budget = 5\n",
    "base_agent = \"AgentDeepThinkPDDL\"\n",
    "prompt_args_hypervisor = {\n",
    "    \"human_specification\": specification,\n",
    "    \"plan\": \"No plan yet.\",\n",
    "    \"specification\": env.config_data,\n",
    "    \"pddl_domain\": domain,\n",
    "    \"pddl_problem\": problem,\n",
    "    \"target_solver\": target_solver,\n",
    "    \"pddl_plan\": result[\"pddl_plan\"],\n",
    "    \"syntax_errors\": result[\"syntax_errors\"],\n",
    "    \"pddl_logs\": result[\"pddl_logs\"],\n",
    "    \"history\": [],\n",
    "}\n",
    "\n",
    "for j in range(1, budget+1):\n",
    "    print(prompt_args_hypervisor)\n",
    "    hypervisor = Hypervisor(prompt_args_hypervisor)\n",
    "    response = hypervisor.run(model_plan)\n",
    "    \n",
    "    # Dynamically instantiate the agent class\n",
    "    match = re.search(r\"<class>(.*?)</class>\", response, re.DOTALL)\n",
    "    if match:\n",
    "        agent_name = match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"[Warning] No agent class found in the response ({agent_name}). Using default {base_agent}.\")\n",
    "        agent_name = base_agent\n",
    "        \n",
    "    print(\"Agent: \", agent_name)\n",
    "    print(\"Generating the plan with the agent.\")\n",
    "    agent_class = hypervisor.agents[agent_name]\n",
    "    \n",
    "    required_args = {}\n",
    "    for arg in agent_class.required_args.keys():\n",
    "        agent_class.required_args[arg] = prompt_args_hypervisor[arg]\n",
    "        \n",
    "    new_agent = agent_class(model_plan, agent_class.required_args)\n",
    "    response = new_agent.run()\n",
    "    \n",
    "    # The Hypervisor decides the plan is good\n",
    "    if agent_name == \"NoOpAgent\":\n",
    "        break\n",
    "    \n",
    "    # Get domain and plan\n",
    "    domain, problem = pddl_parser.parse(response, from_file=False)\n",
    "    prompt_args_hypervisor[\"pddl_domain\"] = domain\n",
    "    prompt_args_hypervisor[\"pddl_problem\"] = problem\n",
    "    \n",
    "    # Run the pddl planner\n",
    "    with open(BASE_FOLDER / f\"problem_{j}.pddl\", \"w\") as f:\n",
    "        f.write(str(problem))\n",
    "\n",
    "    with open(BASE_FOLDER / f\"domain_{j}.pddl\", \"w\") as f:\n",
    "        f.write(str(domain))\n",
    "\n",
    "    result = solver(\n",
    "        BASE_FOLDER,\n",
    "        BASE_FOLDER / f\"domain_{j}.pddl\",\n",
    "        BASE_FOLDER / f\"problem_{j}.pddl\",\n",
    "        BASE_FOLDER / f\"sas_plan_{j}\",\n",
    "    )\n",
    "\n",
    "    # Update the hypervisor args\n",
    "    for k, v in result.items():\n",
    "        prompt_args_hypervisor[k] = v\n",
    "\n",
    "    # Update the history\n",
    "    prompt_args_hypervisor[\"history\"].append(hypervisor.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm_plan.agent import AgentNaturalLanguage\n",
    "\n",
    "# Produce the natural language plan\n",
    "if Path(BASE_FOLDER / f\"sas_plan_{j}\").exists():\n",
    "    with open(BASE_FOLDER / f\"domain_{j}.pddl\", \"r\") as f:\n",
    "        domain = f.read()\n",
    "\n",
    "    with open(BASE_FOLDER / f\"problem_{j}.pddl\", \"r\") as f:\n",
    "        problem = f.read()\n",
    "\n",
    "    with open(BASE_FOLDER / f\"sas_plan_{j}\", \"r\") as f:\n",
    "        plan = f.read()\n",
    "\n",
    "    prompt_args = {\n",
    "        \"specification\": env.config_data,\n",
    "        \"pddl_domain\": domain,\n",
    "        \"pddl_problem\": problem,\n",
    "        \"pddl_plan\": plan,\n",
    "    }\n",
    "\n",
    "    hypervisor_to_nl = AgentNaturalLanguage(\n",
    "        llm=model_plan, prompt_args=prompt_args\n",
    "    )\n",
    "\n",
    "    natural_plan = hypervisor_to_nl.run()\n",
    "\n",
    "    with open(BASE_FOLDER / \"final_natural_plan.txt\", \"w\") as f:\n",
    "        f.write(natural_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
