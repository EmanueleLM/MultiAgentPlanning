{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from src.llm_plan.LLM import GPT_Ollama\n",
    "\n",
    "model = GPT_Ollama(reasoning=\"low\")\n",
    "\n",
    "# Simulated local LLM API (replace with your real call)\n",
    "def call_local_llm(system_prompt: str, history: str) -> str:\n",
    "    \"\"\"\n",
    "    system_prompt: combined text from all SystemMessages\n",
    "    history: text containing user/assistant messages\n",
    "    \"\"\"\n",
    "    response = model.generate_sync(system_prompt, history)  # Call your local model here\n",
    "    history += \"\\n\" + response  # Append model response to history\n",
    "\n",
    "    return f\"[SYSTEM={system_prompt}] Echo: {history}\"  # mock output\n",
    "\n",
    "# Keep conversation messages\n",
    "conversation = [SystemMessage(content=\"You are a helpful coding assistant.\")]\n",
    "\n",
    "def send_message(user_text: str):\n",
    "    conversation.append(HumanMessage(content=user_text))\n",
    "\n",
    "    # Extract system prompts separately\n",
    "    system_prompts = [m.content for m in conversation if isinstance(m, SystemMessage)]\n",
    "    combined_system_prompt = \"\\n\".join(system_prompts)\n",
    "\n",
    "    # Extract non-system history\n",
    "    history_parts = []\n",
    "    for m in conversation:\n",
    "        if isinstance(m, HumanMessage):\n",
    "            history_parts.append(f\"USER: {m.content}\")\n",
    "        elif isinstance(m, AIMessage):\n",
    "            history_parts.append(f\"ASSISTANT: {m.content}\")\n",
    "    history_text = \"\\n\".join(history_parts)\n",
    "\n",
    "    # Call the local LLM\n",
    "    output_text = call_local_llm(combined_system_prompt, history_text)\n",
    "\n",
    "    # Wrap in AIMessage so LangChain structure is preserved\n",
    "    reply = AIMessage(content=output_text)\n",
    "    conversation.append(reply)\n",
    "\n",
    "    print(\"Assistant:\", reply.content)\n",
    "\n",
    "# Example multi-turn chat\n",
    "send_message(\"Write a short python function. You alwayw reply in upper-case.\")\n",
    "# Change system prompt mid-chat\n",
    "# conversation.append(SystemMessage(content=\"Now you are an assistant that upper-cases everything.\"))\n",
    "send_message(\"Add a docstring to the function.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert Python coder. Your task is to extend existing Python code files with new classes or functions based on the provided task description. You will receive a history of previous interactions, the current file content, and the task description. Please ensure that your code is syntactically correct and follows best practices.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here's a specific of a task I want you to code:\n",
      "A simple single-agent blocks world implementation. You have some stacks of blocks labelled with unique letters. The goal is to rearrange the blocks into another configuration of stacks. You can only move a block if it does not have other blocks on top.\n",
      "\n",
      "Here's Problem.py, a Python file that defines a class for several single-agent and multi-agent problems:\n",
      "\n",
      "from typing import List\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "# This is not a good import practice, but we require it for the agentic framework\n",
      "from src.llm_plan.AgenticFramework import *\n",
      "\n",
      "\n",
      "class Problem(ABC):\n",
      "    \"\"\"\n",
      "    Abstract base class for problems.\n",
      "    Classes that extend Problem should define the specific problem to be solved.\n",
      "    TODO: add methods that are mandatory for any subclasses.\n",
      "    \"\"\"\n",
      "\n",
      "    pass\n",
      "\n",
      "\n",
      "class ProblemStaticAgentsVault(Problem):\n",
      "    def __init__(self, static_agent_vault: StaticAgentsVault):\n",
      "        \"\"\"\n",
      "        Initialize the problem with a StaticAgentsVault instance.\n",
      "\n",
      "        Args:\n",
      "            static_agent_vault (StaticAgentsVault): The static agents vault environment.\n",
      "            This must be initialized before.\n",
      "        \"\"\"\n",
      "        super(ProblemStaticAgentsVault, self).__init__()\n",
      "        self.static_agent_vault = static_agent_vault\n",
      "\n",
      "        # Collect information from the environment and format it\n",
      "        def format_info(info: List | str) -> str:\n",
      "            if isinstance(info, List):\n",
      "                return \"\\n\".join(info) + \"\\n\"\n",
      "            return str(info) + \"\\n\"\n",
      "\n",
      "        self.agent_A_knowledge = format_info(\n",
      "            self.static_agent_vault.knowledge[\"Agent A\"]\n",
      "        )\n",
      "        self.agent_B_knowledge = format_info(\n",
      "            self.static_agent_vault.knowledge[\"Agent B\"]\n",
      "        )\n",
      "        self.agent_A_observables = format_info(\n",
      "            self.static_agent_vault.observables[\"Agent A\"]\n",
      "        )\n",
      "        self.agent_B_observables = format_info(\n",
      "            self.static_agent_vault.observables[\"Agent B\"]\n",
      "        )\n",
      "        self.public_information = format_info(\n",
      "            self.static_agent_vault.public_information\n",
      "        )\n",
      "        self.agent_A_goal = format_info(self.static_agent_vault.goal[\"Agent A\"])\n",
      "        self.agent_B_goal = format_info(self.static_agent_vault.goal[\"Agent B\"])\n",
      "\n",
      "        self.system_prompt_template = (\n",
      "            \"You are an expert with PDDL problems (Planning Domain Definition Language). \\\n",
      "You always provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "        self.prompt = (\n",
      "            \"You are {agent_name}. You are in an enviroment with the following public information:\\n{public_information}\\n\\\n",
      "You have the following knowledge:\\n{agent_knowledge}\\n\\\n",
      "This is the global goal to solve:{goal}\\n\\\n",
      "Think step by step and and provide a PDDL domain and a PDDL problem file to solve the task.\\nIf you miss some information, do not make assumptions,\\\n",
      "just give a plan that concerns the information you have.\"\n",
      "        )\n",
      "        self.orchestrator_prompt = \"There are two agents in an environment. You will receive their PDDL domains and problems.\\n\\\n",
      "You need to orchestrate them to solve the task. Keep in mind that the PDDL they send you may be partial or contain ambiguities.\\n\\\n",
      "A partial PDDL may partially solve a planning problem, but it may require to integrate additional information from the other PDDL to achieve the goal.\\n\\\n",
      "Ambiguities may appear in different forms: for example, two PDDL problems may refer to the same object with different names (e.g., a door for an agent is the entrance for the other).\\n\\\n",
      "Here's the information the first agent has and its PDDL response:\\n\\\n",
      "{pddl_agent_A}\\n\\\n",
      "Here's the information the second agent has and its PDDL response:\\n\\\n",
      "{pddl_agent_B}\\n\\\n",
      "You need to integrate the PDDL responses of the two agents to solve the task. The goal is: {goal}.\\n\\\n",
      "Think step by step and and provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "\n",
      "        self.system_prompts = {\n",
      "            \"Agent A\": self.system_prompt_template,\n",
      "            \"Agent B\": self.system_prompt_template,\n",
      "            \"Orchestrator\": self.system_prompt_template,\n",
      "        }\n",
      "\n",
      "        self.prompts = {\n",
      "            \"Agent A\": self.prompt.format(\n",
      "                agent_name=\"Agent A\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_A_knowledge,\n",
      "                goal=self.agent_A_goal,\n",
      "            ),\n",
      "            \"Agent B\": self.prompt.format(\n",
      "                agent_name=\"Agent B\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_B_knowledge,\n",
      "                goal=self.agent_B_goal,\n",
      "            ),\n",
      "            \"Orchestrator\": self.orchestrator_prompt,  # Need to format this! So probably rethink the code structure\n",
      "        }\n",
      "\n",
      "\n",
      "class ProblemStaticBlocksworld(Problem):\n",
      "    def __init__(self, static_blocksworld: StaticBlocksworld):\n",
      "        \"\"\"\n",
      "        Initialize the problem with a StaticBlocksworld instance.\n",
      "\n",
      "        Args:\n",
      "            static_blocksworld (StaticBlocksworld): The static blocksworld environment.\n",
      "            This must be initialized before.\n",
      "        \"\"\"\n",
      "        super().__init__()\n",
      "        self.static_blocksworld = static_blocksworld\n",
      "\n",
      "        def format_info(info: List | str) -> str:\n",
      "            if isinstance(info, List):\n",
      "                return \"\\n\".join(info) + \"\\n\"\n",
      "            return str(info) + \"\\n\"\n",
      "\n",
      "        self.agent_A_knowledge = format_info(\n",
      "            self.static_blocksworld.knowledge[\"Agent A\"]\n",
      "        )\n",
      "        self.agent_B_knowledge = format_info(\n",
      "            self.static_blocksworld.knowledge[\"Agent B\"]\n",
      "        )\n",
      "        self.agent_A_observables = format_info(\n",
      "            self.static_blocksworld.observables[\"Agent A\"]\n",
      "        )\n",
      "        self.agent_B_observables = format_info(\n",
      "            self.static_blocksworld.observables[\"Agent B\"]\n",
      "        )\n",
      "        self.public_information = format_info(\n",
      "            self.static_blocksworld.public_information\n",
      "        )\n",
      "        self.agent_A_goal = format_info(self.static_blocksworld.goal[\"Agent A\"])\n",
      "        self.agent_B_goal = format_info(self.static_blocksworld.goal[\"Agent B\"])\n",
      "\n",
      "        self.system_prompt_template = (\n",
      "            \"You are an expert with PDDL problems (Planning Domain Definition Language). \\\n",
      "You always provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "        self.prompt = (\n",
      "            \"You are {agent_name}. You are in an enviroment with the following public information:\\n{public_information}\\n\\\n",
      "You have the following knowledge:\\n{agent_knowledge}\\n\\\n",
      "This is the global goal to solve:{goal}\\n\\\n",
      "Think step by step and provide a PDDL domain and a PDDL problem file to solve the task.\\nIf you miss some information, do not make assumptions,\\\n",
      "just give a plan that concerns the information you have.\"\n",
      "        )\n",
      "        self.orchestrator_prompt = (\n",
      "            \"There are two agents in an environment. You will receive their PDDL domains and problems.\\n\\\n",
      "You need to orchestrate them to solve the task. Keep in mind that the PDDL they send you may be partial or contain ambiguities.\\n\\\n",
      "A partial PDDL may partially solve a planning problem, but it may require integrating additional information from the other PDDL to achieve the goal.\\n\\\n",
      "Ambiguities may appear in different forms: for example, two PDDL problems may refer to the same object with different names (e.g., a block for an agent is a cube for the other).\\n\\\n",
      "Here's the information the first agent has and its PDDL response:\\n\\\n",
      "{pddl_agent_A}\\n\\\n",
      "Here's the information the second agent has and its PDDL response:\\n\\\n",
      "{pddl_agent_B}\\n\\\n",
      "You need to integrate the PDDL responses of the two agents to solve the task. The goal is: {goal}.\\n\\\n",
      "Think step by step and provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "\n",
      "        self.system_prompts = {\n",
      "            \"Agent A\": self.system_prompt_template,\n",
      "            \"Agent B\": self.system_prompt_template,\n",
      "            \"Orchestrator\": self.system_prompt_template,\n",
      "        }\n",
      "\n",
      "        self.prompts = {\n",
      "            \"Agent A\": self.prompt.format(\n",
      "                agent_name=\"Agent A\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_A_knowledge,\n",
      "                goal=self.agent_A_goal,\n",
      "            ),\n",
      "            \"Agent B\": self.prompt.format(\n",
      "                agent_name=\"Agent B\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_B_knowledge,\n",
      "                goal=self.agent_B_goal,\n",
      "            ),\n",
      "            \"Orchestrator\": self.orchestrator_prompt,  # Need to format this! So probably rethink the code structure\n",
      "        }\n",
      "\n",
      "\n",
      "class ProblemStaticThreeSwitchesRoom(Problem):\n",
      "    def __init__(self, static_three_switches_room: StaticThreeSwitchesRoom):\n",
      "        \"\"\"\n",
      "        Problem definition for the Three Switches Room environment.\n",
      "        \"\"\"\n",
      "        super().__init__()\n",
      "        self.env = static_three_switches_room\n",
      "\n",
      "        def fmt(info: List | str) -> str:\n",
      "            return (\n",
      "                \"\\n\".join(info) + \"\\n\" if isinstance(info, List) else str(info) + \"\\n\"\n",
      "            )\n",
      "\n",
      "        self.agent_R_knowledge = fmt(self.env.knowledge[\"Agent R\"])\n",
      "        self.agent_G_knowledge = fmt(self.env.knowledge[\"Agent G\"])\n",
      "        self.agent_B_knowledge = fmt(self.env.knowledge[\"Agent B\"])\n",
      "\n",
      "        self.public_information = fmt(self.env.public_information)\n",
      "        self.agent_R_goal = fmt(self.env.goal[\"Agent R\"])\n",
      "        self.agent_G_goal = fmt(self.env.goal[\"Agent G\"])\n",
      "        self.agent_B_goal = fmt(self.env.goal[\"Agent B\"])\n",
      "\n",
      "        self.system_prompt_template = (\n",
      "            \"You are an expert with PDDL problems (Planning Domain Definition Language). \"\n",
      "            \"You always provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "\n",
      "        self.prompt_template = (\n",
      "            \"You are {agent_name}. You are in an environment with the following public information:\\n{public_information}\\n\"\n",
      "            \"You have the following knowledge:\\n{agent_knowledge}\\n\"\n",
      "            \"This is the global goal to solve:\\n{goal}\\n\"\n",
      "            \"Think step by step and provide a PDDL domain and a PDDL problem file to solve the task.\\n\"\n",
      "            \"If you miss some information, do not make assumptions—just give a plan that concerns the information you have.\"\n",
      "        )\n",
      "\n",
      "        self.orchestrator_prompt = (\n",
      "            \"There are three agents in an environment. You will receive their PDDL domains and problems.\\n\"\n",
      "            \"You need to orchestrate them to solve the task. Keep in mind that the PDDL they send you may be partial or contain ambiguities.\\n\"\n",
      "            \"The goal is for all three switches to be pressed simultaneously to unlock the door.\\n\"\n",
      "            \"A partial PDDL may partially solve a planning problem, but may require integrating additional information from other PDDLs.\\n\"\n",
      "            \"Ambiguities may appear, e.g., objects referred to with different names.\\n\"\n",
      "            \"Here's the information the first agent has and its PDDL response:\\n\"\n",
      "            \"{pddl_agent_R}\\n\"\n",
      "            \"Here's the information the second agent has and its PDDL response:\\n\"\n",
      "            \"{pddl_agent_G}\\n\"\n",
      "            \"Here's the information the third agent has and its PDDL response:\\n\"\n",
      "            \"{pddl_agent_B}\\n\"\n",
      "            \"You need to integrate the PDDL responses of the three agents to solve the task. The goal is: {goal}.\\n\"\n",
      "            \"Think step by step and provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "\n",
      "        self.system_prompts = {\n",
      "            \"Agent R\": self.system_prompt_template,\n",
      "            \"Agent G\": self.system_prompt_template,\n",
      "            \"Agent B\": self.system_prompt_template,\n",
      "            \"Orchestrator\": self.system_prompt_template,\n",
      "        }\n",
      "\n",
      "        self.prompts = {\n",
      "            \"Agent R\": self.prompt_template.format(\n",
      "                agent_name=\"Agent R\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_R_knowledge,\n",
      "                goal=self.agent_R_goal,\n",
      "            ),\n",
      "            \"Agent G\": self.prompt_template.format(\n",
      "                agent_name=\"Agent G\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_G_knowledge,\n",
      "                goal=self.agent_G_goal,\n",
      "            ),\n",
      "            \"Agent B\": self.prompt_template.format(\n",
      "                agent_name=\"Agent B\",\n",
      "                public_information=self.public_information,\n",
      "                agent_knowledge=self.agent_B_knowledge,\n",
      "                goal=self.agent_B_goal,\n",
      "            ),\n",
      "            \"Orchestrator\": self.orchestrator_prompt,\n",
      "        }\n",
      "\n",
      "\n",
      "class ProblemStaticSingleAgentBlocksworld(Problem):\n",
      "    def __init__(self, static_single_blocksworld: StaticSingleAgentBlocksworld):\n",
      "        super().__init__()\n",
      "        self.env = static_single_blocksworld\n",
      "\n",
      "        def fmt(info: List | str) -> str:\n",
      "            return (\n",
      "                \"\\n\".join(info) + \"\\n\" if isinstance(info, List) else str(info) + \"\\n\"\n",
      "            )\n",
      "\n",
      "        self.agent_knowledge = fmt(self.env.knowledge[\"Agent\"])\n",
      "        self.public_information = fmt(self.env.public_information)\n",
      "        self.agent_goal = fmt(self.env.goal[\"Agent\"])\n",
      "\n",
      "        self.system_prompt_template = (\n",
      "            \"You are an expert with PDDL problems (Planning Domain Definition Language). \"\n",
      "            \"You always provide a PDDL domain and a PDDL problem file to solve the task.\"\n",
      "        )\n",
      "\n",
      "        self.prompt = (\n",
      "            \"You are the only agent in an environment with the following public information:\\n\"\n",
      "            \"{public_information}\\n\"\n",
      "            \"You have the following knowledge:\\n\"\n",
      "            \"{agent_knowledge}\\n\"\n",
      "            \"This is the global goal to solve:\\n\"\n",
      "            \"{goal}\\n\"\n",
      "            \"Think step by step and provide a PDDL domain and a PDDL problem file to solve the task.\\n\"\n",
      "            \"If you miss some information, do not make assumptions—just give a plan that concerns the information you have.\"\n",
      "        ).format(\n",
      "            public_information=self.public_information,\n",
      "            agent_knowledge=self.agent_knowledge,\n",
      "            goal=self.agent_goal,\n",
      "        )\n",
      "\n",
      "        self.system_prompts = {\"Agent\": self.system_prompt_template}\n",
      "        self.prompts = {\"Agent\": self.prompt}\n",
      "\n",
      "\n",
      "Here's Environment.py, a Python file that defines a class for several single-agent and multi-agent environments and wraps a problem defined in Problem.py: \n",
      "\n",
      "import itertools\n",
      "import random\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import List\n",
      "\n",
      "\n",
      "class StaticEnviroment(ABC):\n",
      "    \"\"\"\n",
      "    Abstract base class for static environments.\n",
      "    Classes that extend StaticEnvironment should encompass only cases where:\n",
      "    - the environment does not change;\n",
      "    - the agents cannot explore.\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def render(self):\n",
      "        \"\"\"\n",
      "        Render the current state of the environment.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def reset(self):\n",
      "        \"\"\"\n",
      "        Reset the environment.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "class StaticAgentsVault(StaticEnviroment):\n",
      "    def __init__(self, grid_size: int = 4, visibility: List[int] | int = [1, 1]):\n",
      "        \"\"\"A grid where two agents (Agent A and Agent B) are places randomly on the border, with a 'vault' in the middle.\n",
      "        Agents cannot move: they have to provide a plan given the current observations they have of the environemnt.\n",
      "\n",
      "        Args:\n",
      "            grid_size (int, optional): Size of the grid: each agent occupies one cell. Defaults to 4.\n",
      "            visibility (List[int], optional): The number of cells around an agent they can see. Defaults to [1, 1]. Diagonals included.\n",
      "\n",
      "        Please notice that in this problem, the position of the agents and the vault are only used to compute the visibilty.\n",
      "        The actions we expect the agents come up with are reach_the_vault and not move_up, move_down, etc.\n",
      "        \"\"\"\n",
      "        super(StaticAgentsVault, self).__init__()\n",
      "        self.grid_size = grid_size\n",
      "        self.visibility = (\n",
      "            [visibility, visibility] if isinstance(visibility, int) else visibility\n",
      "        )\n",
      "\n",
      "        # Public information available to anyone in the environment\n",
      "        self.public_information = [\n",
      "            \"There is a vault in the environment.\",\n",
      "            \"The vault is closed.\",\n",
      "            \"The vault requires a key to be opened.\",\n",
      "            \"The entrance of the vault is small.\",\n",
      "        ]\n",
      "\n",
      "        # What the agents see and know\n",
      "        self.knowledge = {\n",
      "            \"Agent A\": [\n",
      "                \"I have the key to open the vault.\",\n",
      "                \"I am a big robot. I cannot enter the vault to grab the object, even if it is open.\",\n",
      "                \"There may be another collaborative agent in the environment.\",\n",
      "            ],\n",
      "            \"Agent B\": [\n",
      "                \"I do not have the key to open the vault.\",\n",
      "                \"I am a small robot. If the vault is open, I can enter and grab the object.\",\n",
      "                \"There may be another collaborative agent in the environment.\",\n",
      "            ],\n",
      "        }\n",
      "\n",
      "        # What another agent observe if they can see one of the objects in the dictionary\n",
      "        self.observables = {\n",
      "            \"Agent A\": [\n",
      "                \"Agent A has the key to open the vault.\",\n",
      "                \"Agent A cannot enter the vault to grab the object.\",\n",
      "            ],\n",
      "            \"Agent B\": [\"Agent B can enter the vault to grab the object.\"],\n",
      "        }\n",
      "\n",
      "        # The overall goal\n",
      "        self.goal = {\n",
      "            \"Agent A\": \"Open the vault and grab the object inside.\",\n",
      "            \"Agent B\": \"Open the vault and grab the object inside.\",\n",
      "        }\n",
      "\n",
      "        self.reset()  # Call reset to initialize the environment\n",
      "\n",
      "    def reset(self):\n",
      "        \"\"\"\n",
      "        Randomly re-initialize the environment.\n",
      "        \"\"\"\n",
      "        # Sample three unique positions for the two agents and the vault\n",
      "        _grid_range = range(self.grid_size)\n",
      "        _all_positions = list(\n",
      "            itertools.product(_grid_range, _grid_range)\n",
      "        )  # Generate all possible unique positions on the grid\n",
      "        _positions = random.sample(_all_positions, 3)  # Sample without replacement\n",
      "        self.positions = {\n",
      "            \"Agent A\": _positions[0],\n",
      "            \"Agent B\": _positions[1],\n",
      "            \"Vault\": _positions[2],\n",
      "        }\n",
      "\n",
      "        # Re-initialize knowledge based on visibility\n",
      "        # Reset knowledge to its base state before adding observables\n",
      "        self.knowledge = {\n",
      "            \"Agent A\": [\n",
      "                \"I am a big robot.\",\n",
      "                \"The vault is closed.\",\n",
      "                \"I have the key to open the vault.\",\n",
      "                \"I cannot grab the object inside the vault.\",\n",
      "            ],\n",
      "            \"Agent B\": [\n",
      "                \"I am a small robot\",\n",
      "                \"The vault is closed.\",\n",
      "                \"I do not have the key to open the vault.\",\n",
      "                \"If the vault is open, I can enter and grab the object.\",\n",
      "            ],\n",
      "        }\n",
      "\n",
      "        def x_sees_y(x_pos: List[int], y_pos: List[int], r: float) -> bool:\n",
      "            \"\"\"\n",
      "            Checks if agent at x_pos can see object at y_pos within a given radius r.\n",
      "            This correctly uses absolute differences for both x and y coordinates.\n",
      "            \"\"\"\n",
      "            return abs(x_pos[0] - y_pos[0]) <= r and abs(x_pos[1] - y_pos[1]) <= r\n",
      "\n",
      "        self.a_sees_b = x_sees_y(\n",
      "            self.positions[\"Agent A\"], self.positions[\"Agent B\"], self.visibility[0]\n",
      "        )\n",
      "        self.b_sees_a = x_sees_y(\n",
      "            self.positions[\"Agent B\"], self.positions[\"Agent A\"], self.visibility[1]\n",
      "        )\n",
      "\n",
      "        if self.a_sees_b:\n",
      "            # Agent A observes Agent B, so add Agent B's observables\n",
      "            self.knowledge[\"Agent A\"].extend(self.observables[\"Agent B\"])\n",
      "\n",
      "        if self.b_sees_a:\n",
      "            # Agent B observes Agent A, so add Agent A's observables\n",
      "            self.knowledge[\"Agent B\"].extend(self.observables[\"Agent A\"])\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"\n",
      "        Renders the current state of the environment.\n",
      "        \"\"\"\n",
      "        print(\"--- Static Agents Vault Environment ---\")\n",
      "        print(f\"Goal: {self.goal}\")\n",
      "\n",
      "        print(\"\\n--- Positions ---\")\n",
      "        for entity, pos in self.positions.items():\n",
      "            print(f\"{entity}: {pos}\")\n",
      "        print(f\"Agent A sees B: {self.a_sees_b}\")\n",
      "        print(f\"Agent A sees B: {self.b_sees_a}\")\n",
      "\n",
      "        print(\"\\n--- Knowledge of Agents ---\")\n",
      "        for agent, knowledge in self.knowledge.items():\n",
      "            print(f\"{agent}:\")\n",
      "            for item in knowledge:\n",
      "                print(f\"  - {item}\")\n",
      "\n",
      "        print(\"\\n--- Public Information ---\")\n",
      "        for info in self.public_information:\n",
      "            print(f\" - {info}\")\n",
      "\n",
      "        grid = []\n",
      "        for y in range(self.grid_size):\n",
      "            row = []\n",
      "            for x in range(self.grid_size):\n",
      "                row.append(\".\")  # Initialize each cell with a blank character\n",
      "            grid.append(row)\n",
      "\n",
      "        # Place the agents and the vault on the grid\n",
      "        for entity, pos in self.positions.items():\n",
      "            x, y = pos\n",
      "            if entity == \"Agent A\":\n",
      "                grid[y][x] = \"A\"\n",
      "            elif entity == \"Agent B\":\n",
      "                grid[y][x] = \"B\"\n",
      "            elif entity == \"Vault\":\n",
      "                grid[y][x] = \"V\"\n",
      "\n",
      "        # Print the grid\n",
      "        print(\"\\n--- Grid ---\")\n",
      "        for row in grid:\n",
      "            print(\" \".join(row))\n",
      "        print(\"--- Legend ---\")\n",
      "        print(\"--- A: Agent A, B: Agent B, V: Vault ---\")\n",
      "        print(\"-------------------------------------\")\n",
      "\n",
      "\n",
      "class StaticBlocksworld(StaticEnviroment):\n",
      "    def __init__(self, num_vowels: int = 3, num_consonants: int = 3, easy: bool = True):\n",
      "        super().__init__()\n",
      "        \"\"\"Two body-less agents A and B are in an environment with blocks labelled by letters. Agent A can only move vowel blocks\n",
      "        and agent B can only move consonant blocks. The goal is to rearrange and restack blocks from one configuration to another.\n",
      "\n",
      "        Args:\n",
      "            num_vowels (int, optional): Number of vowel blocks in the environment. Defualts to 3.\n",
      "            num_consonants (int, optional): Number of consonant blocks in the environment. Defaults to 3.\n",
      "            easy (bool, optional): Whether easy mode is enabled. When easy mode is enabled, instances start with each block\n",
      "            occupying their own stack, i.e. there are the same number of blocks as stacks, and no unstacking will be required. Defaults\n",
      "            to True. If disabled, will start with a random stacked arrangement.\n",
      "        \"\"\"\n",
      "        self.num_vowels = num_vowels\n",
      "        self.num_consonants = num_consonants\n",
      "        self.easy = easy\n",
      "        self.vowels = [\"A\", \"E\", \"I\", \"O\", \"U\"]\n",
      "        self.consonants = [\n",
      "            \"B\",\n",
      "            \"C\",\n",
      "            \"D\",\n",
      "            \"F\",\n",
      "            \"G\",\n",
      "            \"H\",\n",
      "            \"J\",\n",
      "            \"K\",\n",
      "            \"L\",\n",
      "            \"M\",\n",
      "            \"N\",\n",
      "            \"P\",\n",
      "            \"Q\",\n",
      "            \"R\",\n",
      "            \"S\",\n",
      "            \"T\",\n",
      "            \"V\",\n",
      "            \"W\",\n",
      "            \"X\",\n",
      "            \"Y\",\n",
      "            \"Z\",\n",
      "        ]\n",
      "        self.letters = self.vowels + self.consonants\n",
      "        self.public_information = [\n",
      "            \"I am playing with a set of blocks where I need to arrange the blocks into stacks.\"\n",
      "            \"I can perform the following actions: pick up a block; unstack a block from on top\"\n",
      "            \"of another block; put down a block; stack a block on top of another block.\",\n",
      "            \"I can only pick up or unstack one block at a time.\",\n",
      "            \"I can only pick up or unstack a block if my hand is empty.\",\n",
      "            \"I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other\"\n",
      "            \"blocks on top of it and if the block is not picked up.\",\n",
      "            \"I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\",\n",
      "            \"I can only unstack a block from on top of another block if the block I am unstacking is clear.\",\n",
      "            \"Once I pick up or unstack a block, I am holding the block.\",\n",
      "            \"I can only put down a block that I am holding.\",\n",
      "            \"I can only stack a block on top of another block if I am holding the block being stacked.\",\n",
      "            \"I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\",\n",
      "            \"Once I put down or stack a block, my hand becomes empty.\",\n",
      "            \"Once you stack a block on top of a second block, the second block is no longer clear.\",\n",
      "        ]\n",
      "\n",
      "        self.knowledge = {\n",
      "            \"Agent A\": [\n",
      "                \"I can only perform any action on a block if the block is a vowel.\",\n",
      "            ],\n",
      "            \"Agent B\": [\n",
      "                \"I can only perform any action on a block if the block is a consonant.\",\n",
      "            ],\n",
      "        }\n",
      "\n",
      "        self.observables = {\n",
      "            \"Agent A\": [\"Agent A can move the vowel blocks\"],\n",
      "            \"Agent B\": [\"Agent B can move the consonant blocks\"],\n",
      "        }\n",
      "\n",
      "        # reset() will populate goal and add the initial block arrangement to public information - these are different across instances\n",
      "        self.goal: dict = {}\n",
      "        self._blocks_init: List[List[str]] = []\n",
      "        self._blocks_goal: List[List[str]] = []\n",
      "\n",
      "        self.reset()\n",
      "\n",
      "    def reset(self) -> None:\n",
      "        \"\"\"Randomly initializes a block arrangement\"\"\"\n",
      "        num_v, num_c = self.num_vowels, self.num_consonants\n",
      "        v = random.sample(self.vowels, num_v)\n",
      "        c = random.sample(self.consonants, num_c)\n",
      "        letters = v + c\n",
      "        total = num_v + num_c\n",
      "        if num_v + num_c < 2 or not (0 <= num_v <= 5) or not (0 <= num_c <= 21):\n",
      "            raise ValueError(\n",
      "                f\"Invalid number of blocks specified. Must have ar least 2 blocks in total, not {num_v + num_c}!\"\n",
      "            )\n",
      "\n",
      "        bins = total\n",
      "        if not self.easy:\n",
      "            bins = random.randint(1, total - 1)\n",
      "\n",
      "        def get_arrangement(bins: int, letters: List[str]) -> List[List[str]]:\n",
      "            \"\"\"Assigns a random arrangement for the blocks occupying exactly bins stacks.\"\"\"\n",
      "            bases = random.sample(letters, bins)\n",
      "            stacks = [[letter] for letter in bases]\n",
      "            remaining = list(set(letters) - set(bases))\n",
      "            indices = random.choices(range(bins), k=len(remaining))\n",
      "            for _, idx in enumerate(indices):\n",
      "                stacks[idx].append(remaining.pop())\n",
      "            return stacks\n",
      "\n",
      "        def get_description(stacks: List[List[str]]) -> str:\n",
      "            \"\"\"\n",
      "            Given stacks of uniquely labeled blocks (bottom at index 0), return a concatenated string of facts:\n",
      "            - 'the A block is on the table' for each bottom block A\n",
      "            - 'the block X is on top of the Y block' for each adjacent pair\n",
      "            - 'the block Z is clear' for each top block Z\n",
      "            \"\"\"\n",
      "            facts = []\n",
      "\n",
      "            for stack in stacks:\n",
      "                bottom = stack[0]\n",
      "                facts.append(f\"the {bottom} block is on the table\")\n",
      "\n",
      "                for below, above in zip(stack, stack[1:]):\n",
      "                    facts.append(f\"the block {above} is on top of the {below} block\")\n",
      "\n",
      "                top = stack[-1]\n",
      "                facts.append(f\"the block {top} is clear\")\n",
      "\n",
      "            if len(facts) == 1:\n",
      "                return facts[0] + \".\"\n",
      "\n",
      "            return \", \".join(facts[:-1]) + \", and \" + facts[-1] + \".\"\n",
      "\n",
      "        init_stack = get_arrangement(bins, letters)\n",
      "        goal_stack = init_stack\n",
      "        while init_stack == goal_stack:\n",
      "            goal_stack = get_arrangement(random.randint(1, total - 1), letters)\n",
      "        self._blocks_init = init_stack\n",
      "        self._blocks_goal = goal_stack\n",
      "\n",
      "        # Generate descriptions of the stacks and update the corresponding information attributes\n",
      "        init_desc = get_description(self._blocks_init)\n",
      "        goal_desc = get_description(self._blocks_goal)\n",
      "        # goal_desc = goal_desc[0].upper() + goal_desc[1:]\n",
      "        self.public_information.append(f\"As initial conditions I have that {init_desc}\")\n",
      "        self.goal[\"Agent A\"] = f\"To use the available actions so that {goal_desc}\"\n",
      "        self.goal[\"Agent B\"] = f\"To use the available actions so that {goal_desc}\"\n",
      "\n",
      "    def render(self, config: str = \"init\") -> None:\n",
      "        \"\"\"\n",
      "        Renders the block stacks.\n",
      "        Args:\n",
      "            config (str, optional): Specifies which configuration to render, 'init' or 'goal'. Defaults to 'init'.\n",
      "        \"\"\"\n",
      "        if config == \"init\":\n",
      "            stacks = self._blocks_init\n",
      "        elif config == \"goal\":\n",
      "            stacks = self._blocks_goal\n",
      "        else:\n",
      "            raise ValueError(f\"Invalid config '{config}'. Expected 'init' or 'goal'.\")\n",
      "\n",
      "        sep = \"    \"\n",
      "        max_h = max((len(s) for s in stacks), default=0)\n",
      "        rows = [\n",
      "            sep.join([stack[h] if len(stack) > h else \" \" for stack in stacks])\n",
      "            for h in range(max_h)\n",
      "        ]\n",
      "        out = \"\\n\".join(rows[::-1])\n",
      "        print(out)\n",
      "\n",
      "\n",
      "class StaticThreeSwitchesRoom(StaticEnviroment):\n",
      "    def __init__(self, grid_size: int = 4, visibility: List[int] | int = 1):\n",
      "        \"\"\"\n",
      "        A 4x4 grid with three agents (R, G, B), three corresponding switches, and a locked door.\n",
      "        The door opens only if all three agents are on their respective switches at the same time.\n",
      "\n",
      "        Args:\n",
      "            grid_size (int): Size of the grid. Defaults to 4.\n",
      "            visibility (List[int] | int): Vision radius per agent. Defaults to 1 (can see adjacent cells including diagonals).\n",
      "        \"\"\"\n",
      "        super().__init__()\n",
      "        self.grid_size = grid_size\n",
      "        self.visibility = (\n",
      "            [visibility] * 3 if isinstance(visibility, int) else visibility\n",
      "        )\n",
      "\n",
      "        # Public facts\n",
      "        self.public_information = [\n",
      "            \"There is a locked door in the room.\",\n",
      "            \"There are three pressure-sensitive switches: red, green, and blue.\",\n",
      "            \"The door will open only if all three switches are pressed simultaneously.\",\n",
      "        ]\n",
      "\n",
      "        # Knowledge per agent\n",
      "        self.knowledge = {\n",
      "            \"Agent R\": [\n",
      "                \"I am Agent R (Red).\",\n",
      "                \"My objective is to press the red switch.\",\n",
      "                \"I can move Up, Down, Left, Right, or Stay.\",\n",
      "            ],\n",
      "            \"Agent G\": [\n",
      "                \"I am Agent G (Green).\",\n",
      "                \"My objective is to press the green switch.\",\n",
      "                \"I can move Up, Down, Left, Right, or Stay.\",\n",
      "            ],\n",
      "            \"Agent B\": [\n",
      "                \"I am Agent B (Blue).\",\n",
      "                \"My objective is to press the blue switch.\",\n",
      "                \"I can move Up, Down, Left, Right, or Stay.\",\n",
      "            ],\n",
      "        }\n",
      "\n",
      "        # Observable info\n",
      "        self.observables = {\n",
      "            \"Agent R\": [\"Agent R can move towards and press the red switch.\"],\n",
      "            \"Agent G\": [\"Agent G can move towards and press the green switch.\"],\n",
      "            \"Agent B\": [\"Agent B can move towards and press the blue switch.\"],\n",
      "        }\n",
      "\n",
      "        # Goal\n",
      "        self.goal = {\n",
      "            \"Agent R\": \"Coordinate with Agents G and B so that all switches are pressed at the same time to unlock the door.\",\n",
      "            \"Agent G\": \"Coordinate with Agents R and B so that all switches are pressed at the same time to unlock the door.\",\n",
      "            \"Agent B\": \"Coordinate with Agents R and G so that all switches are pressed at the same time to unlock the door.\",\n",
      "        }\n",
      "\n",
      "        self.reset()\n",
      "\n",
      "    def reset(self):\n",
      "        \"\"\"\n",
      "        Randomly place agents, switches, and door in the grid.\n",
      "        \"\"\"\n",
      "        positions = list(\n",
      "            itertools.product(range(self.grid_size), range(self.grid_size))\n",
      "        )\n",
      "        chosen_positions = random.sample(positions, 7)  # 3 agents, 3 switches, 1 door\n",
      "\n",
      "        self.positions = {\n",
      "            \"Agent R\": chosen_positions[0],\n",
      "            \"Agent G\": chosen_positions[1],\n",
      "            \"Agent B\": chosen_positions[2],\n",
      "            \"Red Switch\": chosen_positions[3],\n",
      "            \"Green Switch\": chosen_positions[4],\n",
      "            \"Blue Switch\": chosen_positions[5],\n",
      "            \"Door\": chosen_positions[6],\n",
      "        }\n",
      "\n",
      "        def can_see(agent_pos, object_pos, r):\n",
      "            return (\n",
      "                abs(agent_pos[0] - object_pos[0]) <= r\n",
      "                and abs(agent_pos[1] - object_pos[1]) <= r\n",
      "            )\n",
      "\n",
      "        # Reset visibility-based knowledge\n",
      "        for agent in [\"Agent R\", \"Agent G\", \"Agent B\"]:\n",
      "            base_knowledge = [\n",
      "                f\"I am {agent}.\",\n",
      "                f\"My target is the {agent.split()[1].lower()} switch.\",\n",
      "                \"I can move Up, Down, Left, Right, or Stay.\",\n",
      "            ]\n",
      "            self.knowledge[agent] = base_knowledge.copy()\n",
      "\n",
      "            # Add visible objects\n",
      "            for obj in [\"Red Switch\", \"Green Switch\", \"Blue Switch\", \"Door\"]:\n",
      "                if can_see(\n",
      "                    self.positions[agent], self.positions[obj], self.visibility[0]\n",
      "                ):\n",
      "                    self.knowledge[agent].append(\n",
      "                        f\"I can see the {obj} at position {self.positions[obj]}.\"\n",
      "                    )\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"\n",
      "        Display the environment grid.\n",
      "        \"\"\"\n",
      "        print(\"--- Three Switches Room ---\")\n",
      "        print(f\"Goal: All three switches pressed at the same time to unlock the door.\")\n",
      "\n",
      "        print(\"\\n--- Positions ---\")\n",
      "        for entity, pos in self.positions.items():\n",
      "            print(f\"{entity}: {pos}\")\n",
      "\n",
      "        print(\"\\n--- Knowledge ---\")\n",
      "        for agent, facts in self.knowledge.items():\n",
      "            print(f\"{agent}:\")\n",
      "            for fact in facts:\n",
      "                print(f\"  - {fact}\")\n",
      "\n",
      "        print(\"\\n--- Public Information ---\")\n",
      "        for info in self.public_information:\n",
      "            print(f\" - {info}\")\n",
      "\n",
      "        grid = [[\".\" for _ in range(self.grid_size)] for _ in range(self.grid_size)]\n",
      "\n",
      "        symbols = {\n",
      "            \"Agent R\": \"R\",\n",
      "            \"Agent G\": \"G\",\n",
      "            \"Agent B\": \"B\",\n",
      "            \"Red Switch\": \"r\",\n",
      "            \"Green Switch\": \"g\",\n",
      "            \"Blue Switch\": \"b\",\n",
      "            \"Door\": \"D\",\n",
      "        }\n",
      "\n",
      "        for entity, (x, y) in self.positions.items():\n",
      "            grid[y][x] = symbols[entity]\n",
      "\n",
      "        print(\"\\n--- Grid ---\")\n",
      "        for row in grid:\n",
      "            print(\" \".join(row))\n",
      "        print(\"--- Legend ---\")\n",
      "        print(\"R/G/B: Agents | r/g/b: Switches | D: Door\")\n",
      "\n",
      "\n",
      "class StaticSingleAgentBlocksworld(StaticEnviroment):\n",
      "    def __init__(self, num_blocks: int = 5, easy: bool = True):\n",
      "        \"\"\"\n",
      "        Single-agent version of the blocks world problem.\n",
      "\n",
      "        Args:\n",
      "            num_blocks (int): Number of uniquely labeled blocks. Defaults to 5.\n",
      "            easy (bool): If True, start with each block in its own stack.\n",
      "        \"\"\"\n",
      "        super().__init__()\n",
      "        if num_blocks < 2:\n",
      "            raise ValueError(\"There must be at least 2 blocks.\")\n",
      "        self.num_blocks = num_blocks\n",
      "        self.easy = easy\n",
      "        self.letters = [chr(ord(\"A\") + i) for i in range(num_blocks)]\n",
      "\n",
      "        self.public_information = [\n",
      "            \"I can move blocks between stacks.\",\n",
      "            \"I can only move one block at a time.\",\n",
      "            \"I can only move a block if there is no other block on top of it (the block is clear).\",\n",
      "            \"Once I move a block, I can place it either on the table (start a new stack) or on top of another clear block.\",\n",
      "        ]\n",
      "\n",
      "        self.knowledge = {\n",
      "            \"Agent\": [\n",
      "                \"I am the only agent in this environment.\",\n",
      "                \"I can rearrange blocks according to the rules.\",\n",
      "            ]\n",
      "        }\n",
      "\n",
      "        self.observables = {\"Agent\": [\"This agent can move any block that is clear.\"]}\n",
      "\n",
      "        self.goal = {\"Agent\": \"\"}\n",
      "        self._blocks_init = []\n",
      "        self._blocks_goal = []\n",
      "\n",
      "        self.reset()\n",
      "\n",
      "    def reset(self):\n",
      "        \"\"\"\n",
      "        Initialize random starting and goal configurations.\n",
      "        \"\"\"\n",
      "\n",
      "        def get_arrangement(bins: int, letters: List[str]) -> List[List[str]]:\n",
      "            bases = random.sample(letters, bins)\n",
      "            stacks = [[b] for b in bases]\n",
      "            remaining = list(set(letters) - set(bases))\n",
      "            while remaining:\n",
      "                idx = random.choice(range(len(stacks)))\n",
      "                stacks[idx].append(remaining.pop())\n",
      "            return stacks\n",
      "\n",
      "        def describe(stacks: List[List[str]]) -> str:\n",
      "            facts = []\n",
      "            for stack in stacks:\n",
      "                facts.append(f\"the {stack[0]} block is on the table\")\n",
      "                for below, above in zip(stack, stack[1:]):\n",
      "                    facts.append(f\"the block {above} is on top of the {below} block\")\n",
      "                facts.append(f\"the block {stack[-1]} is clear\")\n",
      "            return \", \".join(facts[:-1]) + \", and \" + facts[-1] + \".\"\n",
      "\n",
      "        bins = self.num_blocks if self.easy else random.randint(1, self.num_blocks)\n",
      "        init_stack = get_arrangement(bins, self.letters)\n",
      "        goal_stack = init_stack\n",
      "        while goal_stack == init_stack:\n",
      "            goal_stack = get_arrangement(\n",
      "                random.randint(1, self.num_blocks), self.letters\n",
      "            )\n",
      "\n",
      "        self._blocks_init = init_stack\n",
      "        self._blocks_goal = goal_stack\n",
      "        self.goal[\"Agent\"] = f\"Rearrange the blocks so that {describe(goal_stack)}\"\n",
      "        self.public_information.append(f\"As initial conditions: {describe(init_stack)}\")\n",
      "\n",
      "    def render(self, config: str = \"init\"):\n",
      "        if config == \"init\":\n",
      "            stacks = self._blocks_init\n",
      "        elif config == \"goal\":\n",
      "            stacks = self._blocks_goal\n",
      "        else:\n",
      "            raise ValueError(\"config must be 'init' or 'goal'.\")\n",
      "\n",
      "        sep = \"    \"\n",
      "        max_h = max(len(s) for s in stacks)\n",
      "        rows = [\n",
      "            sep.join([stack[h] if len(stack) > h else \" \" for stack in stacks])\n",
      "            for h in range(max_h)\n",
      "        ]\n",
      "        print(\"\\n\".join(rows[::-1]))\n",
      "\n",
      "\n",
      "Extend the code in Problem.py with a class named ProblemSingleAgentBlocksWorld to solve the task I gave you at the beginning.\n",
      "Just return the Python class, not the entire code for Problem.py.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alakazam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m task_description = \u001b[33m\"\u001b[39m\u001b[33mA simple single-agent blocks world implementation. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33mYou have some stacks of blocks labelled with unique letters. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33mThe goal is to rearrange the blocks into another configuration of stacks. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33mYou can only move a block if it does not have other blocks on top.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m agent_coder = AgentCoder(model, \u001b[33m\"\u001b[39m\u001b[33mSingleAgentBlocksWorld\u001b[39m\u001b[33m\"\u001b[39m, task_description)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43magent_coder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcode_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproblem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MultiAgentPlanning/src/llm_plan/Agent.py:171\u001b[39m, in \u001b[36mAgentCoder.code_task\u001b[39m\u001b[34m(self, history, task)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[43malakazam\u001b[49m\n\u001b[32m    173\u001b[39m result = \u001b[38;5;28mself\u001b[39m.model.generate_sync(\u001b[38;5;28mself\u001b[39m.system_prompt, prompt)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'alakazam' is not defined"
     ]
    }
   ],
   "source": [
    "from src.llm_plan.Agent import AgentCoder\n",
    "from src.llm_plan.LLM import GPT_Ollama\n",
    "\n",
    "model = GPT_Ollama(reasoning=\"low\")\n",
    "\n",
    "# A description of blocks world\n",
    "task_description = \"A simple single-agent blocks world implementation. \\\n",
    "You have some stacks of blocks labelled with unique letters. \\\n",
    "The goal is to rearrange the blocks into another configuration of stacks. \\\n",
    "You can only move a block if it does not have other blocks on top.\"\n",
    "\n",
    "agent_coder = AgentCoder(model, \"SingleAgentBlocksWorld\", task_description)\n",
    "agent_coder.code_task(history=\"\", task=\"problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_coder.code_task(history=\"<HISTORY>\", task=\"environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment\n",
      "You are an expert Python coder. Your task is to extend existing Python code files with new classes or functions based on the provided task description. You will receive a history of previous interactions, the current file content, and the task description. Please ensure that your code is syntactically correct and follows best practices.\n",
      "\n",
      "\n",
      "\n",
      "<HISTORY>\n",
      "Here's a Python file that defines how to run the experiments once ProblemSingleAgentBlocksWorld and EnvironmentSingleAgentBlocksWorld are defined:\n",
      "\"\"\"\n",
      "Single-Agent Blocks World Experiment Runner\n",
      "Note:\n",
      "- This is a synchronous (non-async) implementation for simplicity.\n",
      "- It runs multiple experiments with alternating easy/hard setups.\n",
      "\"\"\"\n",
      "\n",
      "import subprocess\n",
      "from pathlib import Path\n",
      "\n",
      "from src.llm_plan.LLM import GPT_Ollama\n",
      "from src.llm_plan.Parser import PDDLParser\n",
      "from src.llm_plan.Problem import ProblemStaticSingleAgentBlocksworld\n",
      "from src.llm_plan.Environment import StaticSingleAgentBlocksworld\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    n_experiments = 30\n",
      "    model = GPT_Ollama()\n",
      "    parser = PDDLParser()\n",
      "\n",
      "    # Create base results directories\n",
      "    base_path, offset_paths = (\n",
      "        \"./results/static-single-agent-blocks-world/\",\n",
      "        [\"plans/\", \"log/\", \"pddl/\", \"tmp/\"],\n",
      "    )\n",
      "    for path in offset_paths:\n",
      "        Path(base_path + path).mkdir(parents=True, exist_ok=True)\n",
      "\n",
      "    for experiment in range(n_experiments):\n",
      "        print(f\"Running experiment {experiment + 1} of {n_experiments}\")\n",
      "\n",
      "        easy_mode = True if experiment % 2 == 0 else False\n",
      "        env = StaticSingleAgentBlocksworld(num_blocks=5, easy=easy_mode)\n",
      "        problem = ProblemStaticSingleAgentBlocksworld(env)\n",
      "\n",
      "        # Prompt the single agent for its PDDL problem and domain\n",
      "        print(\"\\tPrompting Agent for the PDDL problem and domain.\")\n",
      "        agent_prompt = f\"Agent Problem:\\n{problem.prompts['Agent']}\\n\"\n",
      "        agent_response = model.generate_sync(\n",
      "            problem.system_prompts[\"Agent\"], problem.prompts[\"Agent\"]\n",
      "        )\n",
      "\n",
      "        # Save raw response\n",
      "        with open(f\"{base_path}tmp/agent_response_exp_{experiment}.txt\", \"w\") as f:\n",
      "            f.write(agent_response)\n",
      "\n",
      "        # Parse PDDL domain and problem from the response\n",
      "        pddl_domain, pddl_problem = parser.parse(\n",
      "            f\"{base_path}tmp/agent_response_exp_{experiment}.txt\"\n",
      "        )\n",
      "\n",
      "        # Save domain & problem\n",
      "        with open(\n",
      "            f\"{base_path}pddl/domain_exp_{experiment}_easy_{easy_mode}.pddl\", \"w\"\n",
      "        ) as domain_file:\n",
      "            domain_file.write(str(pddl_domain))\n",
      "\n",
      "        with open(\n",
      "            f\"{base_path}pddl/problem_exp_{experiment}_easy_{easy_mode}.pddl\", \"w\"\n",
      "        ) as problem_file:\n",
      "            problem_file.write(str(pddl_problem))\n",
      "\n",
      "        # Call the planner\n",
      "        print(\"\\tGenerating the plan using Fast Downward.\")\n",
      "        command = (\n",
      "            f\"./solvers/fast-downward-24.06.1/fast-downward.py --alias lama-first \"\n",
      "            f\"--plan-file {base_path}plans/sas_plan_exp_{experiment}_easy_{easy_mode} \"\n",
      "            f\"{base_path}pddl/domain_exp_{experiment}_easy_{easy_mode}.pddl \"\n",
      "            f\"{base_path}pddl/problem_exp_{experiment}_easy_{easy_mode}.pddl \"\n",
      "            f\"> {base_path}log/log_exp_{experiment}_easy_{easy_mode} 2>&1\"\n",
      "        )\n",
      "\n",
      "        subprocess.run(command, shell=True)\n",
      "        print()\n",
      ".\n",
      "\n",
      "Write the code to run similar experiments as per that file. Just return the Python class, not the entire code.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alakazam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_coder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcode_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<HISTORY>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexperiment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MultiAgentPlanning/src/llm_plan/Agent.py:171\u001b[39m, in \u001b[36mAgentCoder.code_task\u001b[39m\u001b[34m(self, history, task)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[43malakazam\u001b[49m\n\u001b[32m    173\u001b[39m result = \u001b[38;5;28mself\u001b[39m.model.generate_sync(\u001b[38;5;28mself\u001b[39m.system_prompt, prompt)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'alakazam' is not defined"
     ]
    }
   ],
   "source": [
    "agent_coder.code_task(history=\"<HISTORY>\", task=\"experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
