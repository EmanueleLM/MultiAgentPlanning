{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks World\n",
    "\n",
    "An extension of blocks world with two agents.\n",
    "- one can only moves blocks marked with vowels, the other with consonants.\n",
    "\n",
    "The goal is to arrange the blocks according to the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G    I    Q    S    A    E\n"
     ]
    }
   ],
   "source": [
    "from src.llm_plan.LLM import GPT_Ollama\n",
    "from src.llm_plan.Parser import PDDLParser\n",
    "from src.llm_plan.Problem import ProblemStaticBlocksworld\n",
    "from src.llm_plan.StaticEnvironment import StaticBlocksworld\n",
    "\n",
    "model = GPT_Ollama()\n",
    "env = StaticBlocksworld(num_vowels=3, num_consonants=3, easy=True)\n",
    "problem = ProblemStaticBlocksworld(env)\n",
    "parser = PDDLParser()\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Generate the PDDL plans for each agent\n",
    "agents = [\"Agent A\", \"Agent B\"]\n",
    "agent_prompts = {agent: \"\" for agent in agents}\n",
    "agent_responses = {agent: \"\" for agent in agents}\n",
    "\n",
    "for agent in agents:\n",
    "    print(f\"Prompting {model.model_name} with the following prompt:\\n\")\n",
    "    print(problem.prompts[agent])\n",
    "    agent_prompts[agent] = f\"{agent} Problem:\\n\" + problem.prompts[agent] + \"\\n\"\n",
    "    answer = model.generate_sync(problem.system_prompts[agent], \n",
    "                                 problem.prompts[agent])\n",
    "    print(\"Answer:\")\n",
    "    print(answer)\n",
    "    agent_responses[agent] = f\"{agent} Response:\\n\" + answer + \"\\n\"\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the orchestrator for the final plan\n",
    "orchestrator_prompt = problem.prompts[\"Orchestrator\"].format(pddl_agent_A=agent_prompts[\"Agent A\"] + agent_responses[\"Agent A\"],\n",
    "                                                             pddl_agent_B=agent_prompts[\"Agent B\"] + agent_responses[\"Agent B\"],\n",
    "                                                             goal=env.goal[\"Agent A\"])\n",
    "\n",
    "final_plan = model.generate_sync(problem.system_prompts[\"Orchestrator\"], \n",
    "                                 orchestrator_prompt)\n",
    "\n",
    "print(final_plan)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final plan to a file\n",
    "with open(\"./tmp/final_plan_in_text.pddl\", \"w\") as f:\n",
    "    f.write(final_plan)\n",
    "\n",
    "# Isolate the pddl problem and domain\n",
    "pddl_domain, pddl_problem = parser.parse(\"./test/data/sample_pddl.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PDDL domain and problem to files\n",
    "with open(\"./tmp/domain.pddl\", \"w\") as domain_file:\n",
    "    domain_file.write(pddl_domain)\n",
    "\n",
    "with open(\"./tmp/problem.pddl\", \"w\") as problem_file:\n",
    "    problem_file.write(pddl_problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Invoke fast downward and solve the problem\n",
    "command = \"./solvers/fast-downward-24.06.1/fast-downward.py --alias lama-first --plan-file ./tmp/sas_plan ./tmp/domain.pddl ./tmp/problem.pddl > ./tmp/logs.txt 2>&1\"\n",
    "\n",
    "subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
